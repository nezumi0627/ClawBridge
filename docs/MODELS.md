# 🤖 サポートモデル・ガイド

ClawBridge では、用途に応じて最適な AI モデルを選択できます。ここでは特に安定性の高い推奨モデルと、背後で動作するモデル群について解説します。

---

## ✅ 推奨仮想モデル (推奨)

OpenClaw 側での設定を簡略化するため、ClawBridge は以下の 2 つの「仮想モデル ID」を提供しています。

### 1. `claw-model` (ClawBridge Auto - Fast)
- **特徴**: 応答速度と可用性を最優先。
- **内部ルーティング**: `gemini-2.0-flash` や `gpt-4o-mini` の中からその時最も安定しているものへ自動転送。
- **用途**: 日常的なチャット、コード補完、高速なボット応答。
- **設定**: OpenClaw の `primary` モデルとしてデフォルト設定されます。

### 2. `best` (ClawBridge Best - Smart)
- **特徴**: 高い推論能力と正確性を優先。
- **内部ルーティング**: `claude-3.7-sonnet` や `o1-mini` などの最高峰モデルへ転送。
- **用途**: 複雑なプログラミング、論理的推論、データ分析。
- **備考**: 特設の **Tool Polyfill** により、ツール実行の成功率が最も高い構成です。

---

## 🏗️ 個別モデルの詳細

特定のモデルを明示的に指定して使用することも可能です。

### 🔹 Gemini シリーズ (Google経由)
- **`gemini-2.5-flash`**: 2026年時点の最安定版。長文（1Mトークン）に強く、多機能。
- **`gemini-2.0-flash`**: 超高速応答。リアルタイム対話に向いています。

### 🔹 GPT-4 シリーズ (G4F/Pollinations経由)
- **`gpt-4o-mini`**: コスパ最強の高速モデル。
- **`gpt-4o`**: 視覚解析も可能な高性能汎用モデル。

### 🔹 Claude シリーズ (Puter/G4F経由)
- **`claude-3.7-sonnet`**: 世界最高峰のコーディング・推論能力。

---

## 🛠️ モデルの切り替え方法

- **OpenClaw チャット画面**: モデル選択ドロップダウンから選択。
- **設定ファイル**: `openclaw.json` 内の `primary` モデルを `claw-bridge/best` 等に書き換えることで永続化。

> [!TIP]
> 安定性を求める場合は `claw-model`、高い品質が必要な場合は `best` を使用するのが最もスマートな運用です。
